{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from classes import WikiArts\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = r'./output/path_label.csv'\n",
    "path_images = r'./wikiart_500_paintings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform images (normalization, resize, to tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        \n",
    "data = WikiArts(path_labels, path_images, transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [len(data) - 779, 779])\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [len(train_dataset) - 779, 779])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders to load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last fully connected layer by a new one with the number of artists we want to classify. In our example case, let us take 2\n",
    "\n",
    "num_classes = 28 #TO CHANGE REGARDING THE NUMBER OF ARTISTS WE WANT\n",
    "resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=28, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "learning_rate = 0.001\n",
    "mom = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer: SGD\n",
    "#### Loss function: cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(resnet50.parameters(), lr=learning_rate, momentum=mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.589217\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL_PATH = 'best_model_optmiSGD_lossCrossEntrop.pth'\n",
    "BEST_OPTIMIZER_PATH = 'best_optim_optmiSGD_lossCrossEntrop.pth'\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    # Train set\n",
    "    resnet50.train()\n",
    "    # i = 0\n",
    "    for images, labels in iter(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet50(images)\n",
    "        labels=torch.from_numpy(\n",
    "            np.array([labels[i] for i in range (len(labels))])).long()\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # Valid set\n",
    "    resnet50.eval()\n",
    "    valid_error_count = 0.0\n",
    "    for data, target in valid_loader:     \n",
    "        outputs = resnet50(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "        valid_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "\n",
    "    # Comparison valid and test set for each epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # Calculate accuracy for validation dataset\n",
    "    validation_accuracy = 1.0 - float(valid_error_count) / float(len(valid_dataset))\n",
    "    valid_accuracies.append(validation_accuracy)\n",
    "    print('%d: %f' % (epoch, validation_accuracy))\n",
    "    if validation_accuracy > best_accuracy:\n",
    "        torch.save(resnet50.state_dict(), BEST_MODEL_PATH)\n",
    "        torch.save(optimizer.state_dict(), BEST_OPTIMIZER_PATH)\n",
    "        best_accuracy = validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f175daa7640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set: 0.735558\n"
     ]
    }
   ],
   "source": [
    "# Confirm results on test set - with last model\n",
    "    # Test set\n",
    "test_accuracies = []\n",
    "\n",
    "resnet50.eval()\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        outputs = resnet50(images)\n",
    "        for x in outputs:\n",
    "            probabilities = torch.nn.functional.softmax(x, dim=0)\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print('accuracy test set: %f' % (test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set: 0.731707\n"
     ]
    }
   ],
   "source": [
    "# Confirm results on test set - with first model\n",
    "path = 'best_model_optmiSGD_lossCrossEntrop.pth'\n",
    "path_optim = 'best_optim_optmiSGD_lossCrossEntrop.pth'\n",
    "\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes = 28 #TO CHANGE REGARDING THE NUMBER OF ARTISTS WE WANT\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "models.load_state_dict(torch.load(path))\n",
    "\n",
    "models.eval()\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        outputs = models(images)\n",
    "        for x in outputs:\n",
    "            probabilities = torch.nn.functional.softmax(x, dim=0)\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print('accuracy test set: %f' % (test_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
