{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from classes import WikiArts\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = r'./output/path_label.csv'\n",
    "path_images = r'./WikiArt_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform images (normalization, resize, to tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       transforms.Normalize(mean,std)])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        \n",
    "data = WikiArts(path_labels, path_images, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1589, -1.1418, -1.2103,  ..., -1.1247, -1.1247, -1.1247],\n",
       "          [-1.2617, -1.2274, -1.2788,  ..., -1.1760, -1.1760, -1.1589],\n",
       "          [-1.2445, -1.1932, -1.1932,  ..., -1.1932, -1.1932, -1.1760],\n",
       "          ...,\n",
       "          [-1.7069, -1.6898, -1.6555,  ..., -0.1828,  0.0227,  0.2282],\n",
       "          [-1.7069, -1.6727, -1.6555,  ..., -0.1999, -0.0287,  0.1597],\n",
       "          [-1.6213, -1.6213, -1.6555,  ..., -0.2171, -0.0801,  0.0569]],\n",
       " \n",
       "         [[-0.6702, -0.6176, -0.6352,  ..., -0.5826, -0.5651, -0.5651],\n",
       "          [-0.6527, -0.5651, -0.5651,  ..., -0.5651, -0.5651, -0.5301],\n",
       "          [-0.6527, -0.5651, -0.5301,  ..., -0.5651, -0.5651, -0.5476],\n",
       "          ...,\n",
       "          [-1.0728, -1.0553, -1.0203,  ...,  0.1176,  0.3627,  0.5903],\n",
       "          [-1.0728, -1.0378, -1.0203,  ...,  0.1001,  0.3102,  0.5203],\n",
       "          [-0.9853, -0.9853, -1.0203,  ...,  0.0826,  0.2577,  0.4153]],\n",
       " \n",
       "         [[ 0.5485,  0.6879,  0.7751,  ...,  0.7228,  0.7402,  0.7402],\n",
       "          [ 0.6008,  0.7054,  0.7402,  ...,  0.7925,  0.8099,  0.8448],\n",
       "          [ 0.6356,  0.7054,  0.7054,  ...,  0.7925,  0.8099,  0.8274],\n",
       "          ...,\n",
       "          [ 0.7228,  0.7402,  0.7751,  ...,  1.4025,  1.4548,  1.6117],\n",
       "          [ 0.7228,  0.7576,  0.7751,  ...,  1.3851,  1.4025,  1.5420],\n",
       "          [ 0.8099,  0.8099,  0.7751,  ...,  1.3502,  1.3502,  1.4374]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [len(data) - 2, 2])\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [len(train_dataset) - 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders to load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last fully connected layer by a new one with the number of artists we want to classify. In our example case, let us take 2\n",
    "\n",
    "num_classes = 4 #TO CHANGE REGARDING THE NUMBER OF ARTISTS WE WANT\n",
    "resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=4, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "num_classes = 4 #TO CHANGE REGARDING THE NUMBER OF ARTISTS WE WANT\n",
    "learning_rate = 0.001\n",
    "mom = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer: SGD\n",
    "#### Loss function: cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(resnet50.parameters(), lr=learning_rate, momentum=mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6908, 0.1164, 0.0480, 0.1448], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2981, 0.2225, 0.0476, 0.4317], grad_fn=<SoftmaxBackward0>)\n",
      "0: 0.500000\n",
      "tensor([0.2942, 0.2204, 0.0482, 0.4372], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.6998, 0.1138, 0.0478, 0.1387], grad_fn=<SoftmaxBackward0>)\n",
      "1: 0.500000\n",
      "tensor([0.7101, 0.1102, 0.0476, 0.1321], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2938, 0.2179, 0.0489, 0.4394], grad_fn=<SoftmaxBackward0>)\n",
      "2: 0.500000\n",
      "tensor([0.2932, 0.2147, 0.0498, 0.4423], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7190, 0.1066, 0.0473, 0.1271], grad_fn=<SoftmaxBackward0>)\n",
      "3: 0.500000\n",
      "tensor([0.7284, 0.1027, 0.0470, 0.1219], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2948, 0.2114, 0.0507, 0.4431], grad_fn=<SoftmaxBackward0>)\n",
      "4: 0.500000\n",
      "tensor([0.7366, 0.0991, 0.0467, 0.1176], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2953, 0.2079, 0.0515, 0.4453], grad_fn=<SoftmaxBackward0>)\n",
      "5: 0.500000\n",
      "tensor([0.2995, 0.2032, 0.0521, 0.4452], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7462, 0.0950, 0.0461, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "6: 0.500000\n",
      "tensor([0.3035, 0.1970, 0.0522, 0.4473], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7544, 0.0911, 0.0456, 0.1089], grad_fn=<SoftmaxBackward0>)\n",
      "7: 0.500000\n",
      "tensor([0.7591, 0.0885, 0.0455, 0.1070], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.3034, 0.1920, 0.0526, 0.4519], grad_fn=<SoftmaxBackward0>)\n",
      "8: 0.500000\n",
      "tensor([0.7637, 0.0858, 0.0454, 0.1050], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.3041, 0.1872, 0.0529, 0.4558], grad_fn=<SoftmaxBackward0>)\n",
      "9: 0.500000\n",
      "tensor([0.3036, 0.1829, 0.0530, 0.4605], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7676, 0.0834, 0.0453, 0.1038], grad_fn=<SoftmaxBackward0>)\n",
      "10: 0.500000\n",
      "tensor([0.3044, 0.1801, 0.0532, 0.4623], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7715, 0.0811, 0.0451, 0.1024], grad_fn=<SoftmaxBackward0>)\n",
      "11: 0.500000\n",
      "tensor([0.3060, 0.1778, 0.0533, 0.4629], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7758, 0.0788, 0.0447, 0.1007], grad_fn=<SoftmaxBackward0>)\n",
      "12: 0.500000\n",
      "tensor([0.3068, 0.1762, 0.0535, 0.4636], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7792, 0.0771, 0.0445, 0.0991], grad_fn=<SoftmaxBackward0>)\n",
      "13: 0.500000\n",
      "tensor([0.7826, 0.0754, 0.0443, 0.0978], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.3077, 0.1742, 0.0535, 0.4646], grad_fn=<SoftmaxBackward0>)\n",
      "14: 0.500000\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL_PATH = 'best_model_optmiSGD_lossCrossEntrop.pth'\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    # Train set\n",
    "    resnet50.eval()\n",
    "    for images, labels in iter(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet50(images)\n",
    "        labels=torch.from_numpy(\n",
    "            np.array([labels[i] for i in range (len(labels))])).long()\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # Valid set\n",
    "    resnet50.eval()\n",
    "    valid_error_count = 0.0\n",
    "    for data, target in valid_loader:      \n",
    "        outputs = resnet50(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "        valid_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "\n",
    "    # Comparison valid and test set for each epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # Calculate accuracy for validation dataset\n",
    "    validation_accuracy = 1.0 - float(valid_error_count) / float(len(valid_dataset))\n",
    "    valid_accuracies.append(validation_accuracy)\n",
    "    print('%d: %f' % (epoch, validation_accuracy))\n",
    "    if validation_accuracy > best_accuracy:\n",
    "        torch.save(resnet50.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efb799b2790>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8987, 0.0294, 0.0343, 0.0376])\n",
      "tensor([0.9131, 0.0328, 0.0077, 0.0464])\n",
      "14: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Confirm results on test set\n",
    "    # Test set\n",
    "test_accuracies = []\n",
    "\n",
    "resnet50.eval()\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        outputs = resnet50(images)\n",
    "        for x in outputs:\n",
    "            probabilities = torch.nn.functional.softmax(x, dim=0)\n",
    "            print(probabilities)\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
