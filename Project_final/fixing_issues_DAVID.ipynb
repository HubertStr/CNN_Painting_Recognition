{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from classes import WikiArts\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = r'./output/path_label.csv'\n",
    "path_images = r'./wikiart_500_paintings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_bis(outputs_true, outputs_pred):\n",
    "    '''\n",
    "    Input: \n",
    "        outputs_true: pytorch tensor\n",
    "        outputs_pred: pytorch tensor\n",
    "    '''\n",
    "\n",
    "    path_label_artists = pd.read_csv('./output/path_label_artists.csv')\n",
    "    to_use = path_label_artists[['artist', 'label']].drop_duplicates()\n",
    "    dic = to_use.set_index('label')['artist'].to_dict()\n",
    "\n",
    "    outputs_true = [int(x) for x in sum([list(x) for x in outputs_true], [])]\n",
    "    outputs_pred  = [int(x) for x in sum([list(x) for x in outputs_pred], [])]\n",
    "    outputs_true_artists = list(map(dic.get, outputs_true))\n",
    "    outputs_pred_artists  = list(map(dic.get, outputs_pred))\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (50,10)\n",
    "    cm = confusion_matrix(outputs_true_artists, outputs_pred_artists, labels = list(dic.values()), normalize = 'true')\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=np.round(cm, 2), display_labels = list(dic.values())\n",
    "    )\n",
    "    disp.plot(xticks_rotation= 45.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing images with new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normalized = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "transform_unnormalized = transforms.Compose([transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        \n",
    "data_normalized = WikiArts(path_labels, path_images, transform_normalized)\n",
    "data_unnormalized = WikiArts(path_labels, path_images, transform_unnormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_normalized, test_dataset_normalized = torch.utils.data.random_split(data_normalized, [len(data_normalized) - int(0.15*len(data_normalized)), int(0.15*len(data_normalized))])\n",
    "train_dataset_normalized, valid_dataset_normalized = torch.utils.data.random_split(train_dataset_normalized, [len(train_dataset_normalized) - int(0.15*len(data_normalized)), int(0.15*len(data_normalized))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_unnormalized, test_dataset_unnormalized = torch.utils.data.random_split(data_unnormalized, [len(data_unnormalized) - int(0.15*len(data_unnormalized)), int(0.15*len(data_unnormalized))])\n",
    "train_dataset_unnormalized, valid_dataset_unnormalized = torch.utils.data.random_split(train_dataset_unnormalized, [len(train_dataset_unnormalized) - int(0.15*len(data_unnormalized)), int(0.15*len(data_unnormalized))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing images with data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/home/hub/.local/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14524/1827309342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_set_method1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fixing_issues/test_loader_basic_no_mom.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_set_method2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fixing_issues/test_loader_basic_with_mom.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test_set_method3 = torch.load('./fixing_issues/XXXXX.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_set_method4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fixing_issues/test_loader_lay6and7.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_set_method5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fixing_issues/test_loader_w_2_transf.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/home/hub/.local/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>"
     ]
    }
   ],
   "source": [
    "test_set_method1 = torch.load('./fixing_issues/test_loader_basic_no_mom.pth')\n",
    "test_set_method2 = torch.load('./fixing_issues/test_loader_basic_with_mom.pth')\n",
    "test_set_method3 = torch.load('./fixing_issues/XXXXX.pth')\n",
    "test_set_method4 = torch.load('./fixing_issues/test_loader_lay6and7.pth')\n",
    "test_set_method5 = torch.load('./fixing_issues/test_loader_w_2_transf.pth')\n",
    "test_set_method6 = torch.load('./fixing_issues/test_loader_w_4trasnf.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hub/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_basic_no_mom.pth'\n",
    "\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test set: 0.789643\n"
     ]
    }
   ],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method1):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method1)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "confusion_matrix() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14524/3497971495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix_bis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14524/1760924750.py\u001b[0m in \u001b[0;36mconfusion_matrix_bis\u001b[0;34m(outputs_true, outputs_pred)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_true_artists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_pred_artists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     disp = ConfusionMatrixDisplay(\n\u001b[1;32m     20\u001b[0m         \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_basic_no_mom.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_unnormalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_unnormalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'best_model_optmiSGD_lossCrossEntrop_dav_basic_with_mom.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes = 23\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method2):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method2)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'best_model_optmiSGD_lossCrossEntrop_dav_basic_with_mom.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_unnormalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_unnormalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r''\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method3):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method3)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r''\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_normalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_normalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_lay6and7.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method4):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method4)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_lay6and7.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_normalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_normalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_w_2_transf.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method5):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method5)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_w_2_transf.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_normalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_normalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_w_transf.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_set_method6):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_set_method6)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on new split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = r'./fixing_issues/best_model_optmiSGD_lossCrossEntrop_dav_w_transf.pth'\n",
    "models = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "num_classes, batch_size = 23, 25\n",
    "models.fc = torch.nn.Linear(models.fc.in_features, num_classes)\n",
    "models.load_state_dict(torch.load(path_model))\n",
    "\n",
    "optimizers = optim.SGD(models.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.eval()\n",
    "outputs_pred = []\n",
    "outputs_true = []\n",
    "with torch.no_grad(): \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_dataset_normalized):\n",
    "        outputs = models(images)\n",
    "        outputs_true.append(labels)\n",
    "        outputs_pred.append(outputs.argmax(1))\n",
    "        test_error_count += float(len(labels[labels != outputs.argmax(1)]))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_normalized)*batch_size)\n",
    "    print('accuracy test set: %f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bis(outputs_true, outputs_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
